# Fine-Tuning-LLMs-for-Ollama
This project demonstrates how to fine-tune open-source language models with custom data and then run them locally using Ollama .  It uses Google Colab for training (leveraging free GPUs) and integrates the trained model into Ollama for local inference.
